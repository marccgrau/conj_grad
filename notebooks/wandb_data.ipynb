{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Your project name and optional: entity (username or team name)\n",
    "project_name = \"conj_grad_results\"\n",
    "entity_name = \"marccgrau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sets = {\n",
    "    \"MNIST_MLP_Small\": [\"j2gde3kp\", \"ilwk4wno\", \"guexx00f\", \"tv4niig7\"],\n",
    "    \"MNIST_MLP_Large\": [\"63ali7n8\", \"6zm55eno\", \"b2qnpy74\", \"5ful2rbb\"],\n",
    "    \"MNIST_CNN_Small\": [\"kszrm0ea\", \"0asafs59\", \"2vgne902\", \"ic22ebl7\"],\n",
    "    \"MNIST_CNN_Large\": [\"ujixgcdo\", \"5wuos9yi\", \"t51i5dks\", \"p7pa6auj\"],\n",
    "    \"FASHION_MNIST_MLP_Small\": [\"8r1iwdlm\", \"8fy84vkq\", \"og30l29x\", \"dfrvc4pc\"],\n",
    "    \"FASHION_MNIST_MLP_Large\": [\"bav2ftzc\", \"kzdms3ox\", \"guorim5o\", \"jopq3zzs\"],\n",
    "    \"FASHION_MNIST_CNN_Small\": [\"zbhi3m4v\", \"tvmlui3r\", \"4srm7ig0\", \"49sp1iv0\"],\n",
    "    \"FASHION_MNIST_CNN_Large\": [\"aj0xkyq5\", \"gp0t0ttr\", \"xwebyszi\", \"rqu7d7kz\"],\n",
    "    \"CIFAR10_MLP_Small\": [\"cvnblxwv\", \"o7u7uoel\", \"f41nyx0o\", \"9y1avmjz\"],\n",
    "    \"CIFAR10_MLP_Large\": [\"ugyyag4m\", \"i3jrz9xj\", \"x9p8tk5u\", \"a4kj6di2\"],\n",
    "    \"CIFAR10_CNN_Small\": [\"a1o1h84h\", \"l7vykqin\", \"6z963duj\", \"9xx0jg46\"],\n",
    "    \"CIFAR10_CNN_Large\": [\"zdoxnku5\", \"dwvmuowu\", \"06jvk85p\", \"82gwhc77\"],\n",
    "    \"CIFAR100_MLP_Small\": [\"a94flful\", \"v6wl96y6\", \"l5iyk4v9\", \"xjqitgyg\"],\n",
    "    \"CIFAR100_MLP_Large\": [\"jbw1w7hv\", \"uy0682dq\", \"jw4qwwgp\", \"8cd5h1uq\"],\n",
    "    \"CIFAR100_CNN_Small\": [\"ma3spfwg\", \"kr0kggi4\", \"66rnbay1\", \"1zohaktl\"],\n",
    "    \"CIFAR100_CNN_Large\": [\"a9pu12y0\", \"kcyecx03\", \"12ojnyk5\", \"dmud2b8q\"],\n",
    "    \"SVHN_MLP_Small\": [\"bbic60c6\", \"2eqky0ah\", \"7ju2wb1l\", \"1qbwh5tn\"],\n",
    "    \"SVHN_MLP_Large\": [\"jicl7fsd\", \"svhcuy47\", \"kluj48tv\", \"7p1h9mmn\"],\n",
    "    \"SVHN_CNN_Small\": [\"qss10jlt\", \"99b4sqqd\", \"2ei08gkw\", \"qa8sio24\"],\n",
    "    \"SVHN_CNN_Large\": [\"fodz7vhy\", \"lbc6am62\", \"2fv1ki4e\", \"hnkq207z\"],\n",
    "    \"MAX_ITERS_CIFAR10\": [\"pcffz9ad\", \"hzlfid1d\", \"bebh07m6\", \"cvnblxwv\", \"i490wk2m\", \"wr99r3rv\", \"gogt478c\", \"bgomne1m\", \"9sg89zkk\", \"0g8pf5rr\"],\n",
    "    \"MAX_ITERS_SVHN\": [\"di23fp6s\", \"zt2g483n\", \"dkvzv005\", \"2eqky0ah\", \"7w43iiz4\", \"cj7zb9cx\", \"esyzwpfl\", \"99ue77o6\", \"9a9cci4l\", \"ir3fszqb\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(filename, data):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = {\n",
    "    'nlcg': '#6C5B7B',  # pastel purple\n",
    "    'adam': '#C06C84',  # pastel pink\n",
    "    'rmsprop': '#F67280',  # pastel red\n",
    "    'sgd': '#F8B195',  # pastel orange\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MNIST_MLP_Small saved to ../output/plots/MNIST_MLP_Small_train_loss.png\n",
      "Data for MNIST_MLP_Small saved to ../output/tables/MNIST_MLP_Small_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MNIST_MLP_Large saved to ../output/plots/MNIST_MLP_Large_train_loss.png\n",
      "Data for MNIST_MLP_Large saved to ../output/tables/MNIST_MLP_Large_results.csv\n",
      "Plot for MNIST_CNN saved to ../output/plots/MNIST_CNN_train_loss.png\n",
      "Data for MNIST_CNN saved to ../output/tables/MNIST_CNN_results.csv\n",
      "Plot for FASHION_MNIST_MLP_Small saved to ../output/plots/FASHION_MNIST_MLP_Small_train_loss.png\n",
      "Data for FASHION_MNIST_MLP_Small saved to ../output/tables/FASHION_MNIST_MLP_Small_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for FASHION_MNIST_MLP_Large saved to ../output/plots/FASHION_MNIST_MLP_Large_train_loss.png\n",
      "Data for FASHION_MNIST_MLP_Large saved to ../output/tables/FASHION_MNIST_MLP_Large_results.csv\n",
      "Plot for FASHION_MNIST_CNN saved to ../output/plots/FASHION_MNIST_CNN_train_loss.png\n",
      "Data for FASHION_MNIST_CNN saved to ../output/tables/FASHION_MNIST_CNN_results.csv\n",
      "Plot for CIFAR10_MLP_Small saved to ../output/plots/CIFAR10_MLP_Small_train_loss.png\n",
      "Data for CIFAR10_MLP_Small saved to ../output/tables/CIFAR10_MLP_Small_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for CIFAR10_MLP_Large saved to ../output/plots/CIFAR10_MLP_Large_train_loss.png\n",
      "Data for CIFAR10_MLP_Large saved to ../output/tables/CIFAR10_MLP_Large_results.csv\n",
      "Plot for CIFAR10_CNN saved to ../output/plots/CIFAR10_CNN_train_loss.png\n",
      "Data for CIFAR10_CNN saved to ../output/tables/CIFAR10_CNN_results.csv\n",
      "Plot for CIFAR100_MLP_Small saved to ../output/plots/CIFAR100_MLP_Small_train_loss.png\n",
      "Data for CIFAR100_MLP_Small saved to ../output/tables/CIFAR100_MLP_Small_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for CIFAR100_MLP_Large saved to ../output/plots/CIFAR100_MLP_Large_train_loss.png\n",
      "Data for CIFAR100_MLP_Large saved to ../output/tables/CIFAR100_MLP_Large_results.csv\n",
      "Plot for CIFAR100_CNN saved to ../output/plots/CIFAR100_CNN_train_loss.png\n",
      "Data for CIFAR100_CNN saved to ../output/tables/CIFAR100_CNN_results.csv\n",
      "Plot for SVHN_MLP_Small saved to ../output/plots/SVHN_MLP_Small_train_loss.png\n",
      "Data for SVHN_MLP_Small saved to ../output/tables/SVHN_MLP_Small_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for SVHN_MLP_Large saved to ../output/plots/SVHN_MLP_Large_train_loss.png\n",
      "Data for SVHN_MLP_Large saved to ../output/tables/SVHN_MLP_Large_results.csv\n",
      "Plot for SVHN_CNN saved to ../output/plots/SVHN_CNN_train_loss.png\n",
      "Data for SVHN_CNN saved to ../output/tables/SVHN_CNN_results.csv\n",
      "Plot for MAX_ITERS_CIFAR10 saved to ../output/plots/MAX_ITERS_CIFAR10_train_loss.png\n",
      "Data for MAX_ITERS_CIFAR10 saved to ../output/tables/MAX_ITERS_CIFAR10_results.csv\n",
      "Plot for MAX_ITERS_SVHN saved to ../output/plots/MAX_ITERS_SVHN_train_loss.png\n",
      "Data for MAX_ITERS_SVHN saved to ../output/tables/MAX_ITERS_SVHN_results.csv\n"
     ]
    }
   ],
   "source": [
    "for run_set_name, run_ids in run_sets.items():\n",
    "    csv_data = []\n",
    "    csv_data.append([\"Run ID\", \"Run Name\", \"Optim Name\", \"Created Timestamp\", \"Train Loss\", \"Test Loss\", \"Highest Training Accuracy\", \"Highest Testing Accuracy\", \"Function Calls\", \"Gradient Calls\", \"Total Steps\"])\n",
    "    \n",
    "    train_loss_data = {}\n",
    "    \n",
    "    for run_id in run_ids:\n",
    "        run = api.run(path=f\"marccgrau/conj_grad_results/{run_id}\")\n",
    "        run_config = json.loads(run.json_config)\n",
    "        optim_name = run_config['optimizer']['value']['name']\n",
    "        \n",
    "        # Access logged metrics for the run\n",
    "        history = run.history(keys=[\"_timestamp\", \"loss\", \"val_loss\", \"train_accuracy\", \"test_accuracy\", \"nb_function_calls\", \"nb_gradient_calls\", \"steps\"], samples=50000)\n",
    "        \n",
    "        if optim_name == \"NLCGEager\":\n",
    "            optim_name = \"NLCG\"\n",
    "        if optim_name not in train_loss_data:\n",
    "            train_loss_data[optim_name] = {'steps': [], 'loss': []}\n",
    "        train_loss_data[optim_name]['steps'].extend(history.get('steps', []))\n",
    "        train_loss_data[optim_name]['loss'].extend(history.get('loss', []))\n",
    "        \n",
    "        # Convert the created timestamp to a readable format\n",
    "        created_time = None\n",
    "        if len(history._timestamp) > 0:\n",
    "            created_time = datetime.utcfromtimestamp(history._timestamp[0]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Extract metrics\n",
    "        min_train_loss = min(history.get('loss', [None]))\n",
    "        min_test_loss = min(history.get('val_loss', [None]))\n",
    "        max_train_accuracy = max(history.get('train_accuracy', [None]))\n",
    "        max_test_accuracy = max(history.get('test_accuracy', [None]))\n",
    "        func_calls = max(history.get('nb_function_calls', [None]))\n",
    "        grad_calls = max(history.get('nb_gradient_calls', [None]))\n",
    "        total_steps = max(history.get('steps', [None]))\n",
    "        \n",
    "        # Append data to CSV list\n",
    "        csv_data.append([run.id, run.name, optim_name, created_time, min_train_loss, min_test_loss, max_train_accuracy, max_test_accuracy, func_calls, grad_calls, total_steps])\n",
    "    \n",
    "    # Determine the highest loss value from all the other data series to get a nicer graph\n",
    "    all_other_losses = [data['loss'] for optim_name, data in train_loss_data.items() if optim_name != 'NLCG' and data['loss']]\n",
    "    if all_other_losses:\n",
    "        highest_loss = max([max(losses) for losses in all_other_losses])\n",
    "    else:\n",
    "        highest_loss = 0  # Default value if no losses are found\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for optim_name, data in train_loss_data.items():\n",
    "        # If the optimizer is NLCG, prepend the highest loss value and a 0 step\n",
    "        if optim_name == 'NLCG':\n",
    "            data['loss'].insert(0, highest_loss)\n",
    "            data['steps'].insert(0, 0)\n",
    "        \n",
    "        # Use the color mapping to set the color of the line\n",
    "        plt.plot(data['steps'], data['loss'], label=optim_name, color=color_mapping.get(optim_name.lower()), linewidth=2)\n",
    "\n",
    "\n",
    "    plt.xlabel('Total Steps')\n",
    "    plt.ylabel('Train Loss')\n",
    "    #plt.title(f'Train Loss for {run_set_name.replace(\"_\", \" \")}')\n",
    "\n",
    "    # Remove top and right spines\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Use a light grid\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.5, alpha=0.6)\n",
    "\n",
    "    # Place the legend at the bottom with a transparent background\n",
    "    legend = plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.20), ncol=4, frameon=False)\n",
    "    plt.subplots_adjust(bottom=0.25)  # Adjust the bottom margin to make space for the legend\n",
    "\n",
    "\n",
    "    # Save the plot\n",
    "    plot_filename = f\"../output/plots/{run_set_name}_train_loss.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Plot for {run_set_name} saved to {plot_filename}\")\n",
    "    \n",
    "    # Save the current run set data to a separate CSV\n",
    "    csv_filename = f\"../output/tables/{run_set_name}_results.csv\"\n",
    "    save_to_csv(csv_filename, csv_data)\n",
    "    print(f\"Data for {run_set_name} saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
